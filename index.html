<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors. ">
  <!-- <meta name="keywords" content="SMPLX, Diffusion, Character Animation"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- <h4 class="title conference-title is-4">NeurIPS 2023</h4> -->
            <h2 class="title is-2 publication-title">MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors</h2>
            <div class="is-size-5 publication-authors">

              <span class="author-block">
                <a href="https://github.com/zhanghebuaa">He Zhang</a><sup>1,*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                <a href="https://www.wjrzm.com/">Shenghao Ren</a><sup>3,*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                <a href="https://github.com/haolyuan">Haolei Yuan</a><sup>1,*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">Jianhui Zhao<sup>1</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">Fan Li<sup>1</sup></span>
              <br />
              <span class="author-block">Shuangpeng Sun</span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                Zhenghao Liang<sup>4</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block"><a href="https://ytrock.com/">Tao Yu,✉</a><sup>2</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">Qiu Shen,✉</span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">Xun Cao,✉</span>&nbsp;&nbsp;&nbsp;&nbsp;
              <br />
              <!-- <span class="author-block"></span>
                <a>Anonymous Authors</a>
              </span> -->
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Beihang University</span> &nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block"><sup>2</sup>Tsinghua University</span> 
              <br />
              <span class="author-block"><sup>3</sup>Nanjing University</span> &nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block"><sup>4</sup>Weilan Tech, Beijing</span>
            </div>
            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>International Digital Economy Academy (IDEA),</span>
              <span class="author-block"><sup>2</sup>Shenzhen International Graduate School, Tsinghua University</span>
            </div> -->

            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>*</sup>Equal Contribution &nbsp;&nbsp;</span>
              <span class="author-block"><sup>✉</sup>Corresponding Author</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">

                <!-- PDF Link. -->
                <span class="link-block">
                <a href="https://arxiv.org/abs/2403.17610" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
                <!-- <span class="link-block">
                  <a href="http://arxiv.org/abs/2303.16160" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->

                <!-- Video Link. -->
                <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=s0cG3OVXQUo&t=2s" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->

                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/haolyuan/pressure_tookit" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>MMVP-dataset</span>
                  </a>
                </span>

                <span class="link-block">
                    <a href="https://github.com/wjrzm/VP-MoCap" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>VP-Mocap</span>
                    </a>
                  </span>

                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://drive.google.com" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div> -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h3 class="title is-3 has-text-centered">Video</h3>

        <p align="middle">

          <video id="myVideo" src="./static/videos/v1.mp4" controls></video>

        </p>

      </div>
    </div>
  </section> -->

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h5 class="subtitle is-5">
        <b>MMVP</b> is a a Multimodal MoCap Dataset with Vision and Pressure sensors. It supports provides accurate and dense plantar pressure signals synchronized with RGBD observations.
        </h5>
        <img src="./static/images/teaser.png" autoplay muted loop playsinline height="100%">
      </div>
    </div>
  </section>

  <p style="margin-bottom: -1.5cm;"></p>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            Foot contact is an important cue not only for human motion capture but also for motion understanding and physically plausible motion generation.
            However, most of the foot-contact annotations in existing datasets are estimated by purely visual matching and distance thresholding, which
            results in low accuracy and coarse granularity. Even though existing multimodal datasets synergistically capture plantar pressure (foot contact) and visual signals,
            they are specifically designed for small-range and slow motion such as Taiji Quan and Yoga.
            Therefore, there is still a lack of a vision-pressure multimodal dataset with large-range and fast human motion, as well as accurate and dense
            foot-contact annotation. To fill this gap, we propose a <b>M</b>ultimodal <b>M</b>oCap Dataset with <b>V</b>ision and <b>P</b>ressure sensors, named <b>MMVP</b>.
            MMVP provides accurate and dense plantar pressure signals synchronized with RGBD observations, which is especially useful for both plausible shape
            estimation, robust pose fitting without foot drifting, and accurate global translation tracking. To validate the dataset,
            we propose an RGBD-P SMPL fitting method and also a monocular-video-based baseline framework, VP-MoCap,
            for human motion capture. Experiments demonstrate that our RGBD-P SMPL Fitting results significantly outperform pure visual motion capture.
            Moreover, VP-MoCap outperforms SOTA methods in foot-contact and global translation estimation accuracy.
            We believe the configuration of the dataset and the baseline frameworks will stimulate the research in this direction and also provide a good reference for MoCap applications in various domains.
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <p style="margin-bottom: -0.5cm;"></p>

  <!-- <section class="hero">
    <div class="hero-body has-text-centered">
      <div class="container">
        <h3 class="title is-3">Comparisons with Other Methods</h3>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item agora_1">
            <img src="./static/images/agora_1.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item agora_2">
            <img src="./static/images/agora_2.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item agora_3">
            <img src="./static/images/agora_3.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item agora_4">
            <img src="./static/images/agora_4.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item agora_5">
            <img src="./static/images/agora_5.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ehf_1">
            <img src="./static/images/ehf_1.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>

          <div class="item ehf_2">
            <img src="./static/images/ehf_2.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>

          <div class="item ehf_3">
            <img src="./static/images/ehf_3.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>

          <div class="item ehf_4">
            <img src="./static/images/ehf_4.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_1">
            <img src="./static/images/ubody_1.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_2">
            <img src="./static/images/ubody_2.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_3">
            <img src="./static/images/ubody_3.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_4">
            <img src="./static/images/ubody_4.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_5">
            <img src="./static/images/ubody_5.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>


        </div>
        <h2 class="subtitle has-text-centered">
          From left to right: 1. Input, 2. ExPose, 3. Hand4Whoe, 4. OSX (Ours)
        </h2>
      </div>
    </div>
  </section> -->


  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h3 class="title is-3 has-text-centered">Motion-X Dataset</h3>
        <p align="middle">
          <img src="./static/images/demo.png" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Overview of Motion-X. It includes: (a) diverse facial expressions extracted from BAUM,<br>
          (b) indoor motion with expressive face and hand motions,<br>
          (c) outdoor motion with diverse and challenging poses, and<br>
          (d) several motion sequences.
        </h2>

        <p style="margin-bottom: 1cm;"></p>
        <h3 class="title is-3 has-text-centered">Motion Annotation Pipeline</h3>
        <p align="middle">
          <img src="./static/images/Anno_all.png" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          General Annotation Pipeline.
        </h2>

        <p align="middle">
          <img src="./static/images/Motion_Ann.png" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Motion Annotation Pipeline.
        </h2>

        <p align="middle">
          <img src="./static/images/text_ann.png" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Text Annotation Pipeline.
        </h2>
      </div>
    </div>
  </section> -->

      </div>
    </div>
  </section> -->

  <p style="margin-bottom: -0.5cm;"></p>
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h3 class="title is-3 has-text-centered">Examples in MMVP</h3>
        <p align="middle">
          <img src="./static/videos/MoCap_20230422_172438.gif" width="512" height="512">
          <img src="./static/videos/MoCap_20230422_182056.gif" width="512" height="512">
        </p>
        <!-- <h2 class="subtitle has-text-centered">
          Throw ball        Standing long jump          
        </h2> -->

        <!-- <p align="middle">
          <img src="./static/videos/MoCap_20230422_182056.gif" width="512" height="512">
        </p>
        <h2 class="subtitle has-text-centered">
          Throw ball
        </h2> -->

        <p align="middle">
          <img src="./static/videos/MoCap_20230422_132043.gif" width="512" height="512">
          <img src="./static/videos/MoCap_20230422_151220.gif" width="512" height="512">
        </p>
        <!-- <h2 class="subtitle has-text-centered">
          Side step
        </h2> -->

        <!-- <p align="middle">
          <img src="./static/videos/MoCap_20230422_151220.gif" width="512" height="512">
        </p>
        <h2 class="subtitle has-text-centered">
          Rope skipping
        </h2> -->

      </div>
    </div>
  </section>



  <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
    <source src="./static/videos/demo_video.gif" type="video/mp4">
  </video> -->



  <p style="margin-bottom: -1.5cm;"></p>
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content is-size-6">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{Zhang2024MMVP,
  author    = {He Zhang, Shenghao Ren, Haolei Yuan, Jianhui Zhao, Fan Li, Shuangpeng Sun, Zhenghao Liang, Tao Yu, Qiu Shen, Xun Cao},
  title     = {MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors},
  journal   = {CVPR},
  year      = {2024},
}</code></pre>

<!-- <h2 class="title">Contact Us</h2>
<style>
  ul {
    list-style-type: circle;
  }
</style>
<ul>
  <li>For detailed questions about this work, please contact Jing Lin (jinglin.stu@gmail.com).</li>
  <li>We are looking for talented, motivated, and creative research and engineering interns working on human-centric visual understanding and generation topics. If you are interested, please send your CV to Ailing Zeng (zengailing@idea.edu.cn).</li>
</ul> -->
    </div>
  </section>





  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-size-6">
          <div class="content">
            <p>
              This website is created with this <a href="https://motion-x-dataset.github.io/">template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
