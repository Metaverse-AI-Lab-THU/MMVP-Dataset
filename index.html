<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors. ">
  <!-- <meta name="keywords" content="SMPLX, Diffusion, Character Animation"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- <h4 class="title conference-title is-4">NeurIPS 2023</h4> -->
            <h2 class="title is-2 publication-title">MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors</h2>
            <div class="is-size-5 publication-authors">
              <!--
              <span class="author-block">
                <a href="https://github.com/zhanghebuaa">He Zhang</a><sup>1,*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                <a href="https://www.wjrzm.com/">Shenghao Ren</a><sup>3,*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                <a href="https://github.com/haolyuan">Haolei Yuan</a><sup>1,*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">Jianhui Zhao<sup>1</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">Fan Li<sup>1</sup></span>
              <br />
              <span class="author-block">Shuangpeng Sun<sup>2</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                Zhenghao Liang<sup>4</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block"><a href="https://ytrock.com/">Tao Yu</a><sup>2,✉</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">Qiu Shen<sup>3,✉</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">Xun Cao<sup>3,✉</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <br />
              -->
              <!-- <span class="author-block"></span>
                <a>Anonymous Authors</a>
              </span> -->
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Beihang University</span> &nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block"><sup>2</sup>Tsinghua University</span> 
              <br />
              <span class="author-block"><sup>3</sup>Nanjing University</span> &nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block"><sup>4</sup>Weilan Tech, Beijing</span>
            </div>
            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>International Digital Economy Academy (IDEA),</span>
              <span class="author-block"><sup>2</sup>Shenzhen International Graduate School, Tsinghua University</span>
            </div> -->

            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>*</sup>Equal Contribution &nbsp;&nbsp;</span>
              <span class="author-block"><sup>✉</sup>Corresponding Author</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">

                <!-- PDF Link. -->
                <span class="link-block">
                <a href="https://arxiv.org/abs/2403.17610" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>


                <!-- Video Link. -->
                <span class="link-block">
                <a href="https://youtu.be/sksAVPmlDd8" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>

                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/Metaverse-AI-Lab-THU/MMVP-Dataset/tree/visualizing" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>MMVP-dataset</span>
                  </a>
                </span>


                <span class="link-block">
                  <a href="https://github.com/haolyuan/pressure_tookit" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>RGBD-fitting</span>
                  </a>
                </span>

                <span class="link-block">
                    <a href="https://github.com/wjrzm/VP-MoCap" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>VP-Mocap</span>
                    </a>
                  </span>

                  <!-- https://docs.google.com/forms/d/e/1FAIpQLSf1uLLqXfnVXR2MoyRv5bF9D5gEMc8m8YASa38sTohzVcaVUg/viewform?usp=sf_link -->

                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://docs.google.com/forms/d/e/1FAIpQLSf1uLLqXfnVXR2MoyRv5bF9D5gEMc8m8YASa38sTohzVcaVUg/viewform?usp=sf_link" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Data Access</span>
                  </a>
                </span>


                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://drive.google.com" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div> -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>




  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h3 class="title is-3 has-text-centered">Video</h3>

        <p align="middle">

          <video id="myVideo" src="./static/videos/v1.mp4" controls></video>

        </p>

      </div>
    </div>
  </section> -->

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h5 class="subtitle is-5">
        <b>MMVP</b> is a a Multimodal MoCap Dataset with Vision and Pressure sensors. It supports provides accurate and dense plantar pressure signals synchronized with RGBD observations.
        </h5>
        <img src="./static/images/teaser.png" autoplay muted loop playsinline height="80%">
      </div>
    </div>
  </section>

  <p style="margin-bottom: -1.5cm;"></p>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            Foot contact is an important cue not only for human motion capture but also for motion understanding and physically plausible motion generation.
            However, most of the foot-contact annotations in existing datasets are estimated by purely visual matching and distance thresholding, which
            results in low accuracy and coarse granularity. Even though existing multimodal datasets synergistically capture plantar pressure (foot contact) and visual signals,
            they are specifically designed for small-range and slow motion such as Taiji Quan and Yoga.
            Therefore, there is still a lack of a vision-pressure multimodal dataset with large-range and fast human motion, as well as accurate and dense
            foot-contact annotation. To fill this gap, we propose a <b>M</b>ultimodal <b>M</b>oCap Dataset with <b>V</b>ision and <b>P</b>ressure sensors, named <b>MMVP</b>.
            MMVP provides accurate and dense plantar pressure signals synchronized with RGBD observations, which is especially useful for both plausible shape
            estimation, robust pose fitting without foot drifting, and accurate global translation tracking. To validate the dataset,
            we propose an RGBD-P SMPL fitting method and also a monocular-video-based baseline framework, VP-MoCap,
            for human motion capture. Experiments demonstrate that our RGBD-P SMPL Fitting results significantly outperform pure visual motion capture.
            Moreover, VP-MoCap outperforms SOTA methods in foot-contact and global translation estimation accuracy.
            We believe the configuration of the dataset and the baseline frameworks will stimulate the research in this direction and also provide a good reference for MoCap applications in various domains.
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
      

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/sksAVPmlDd8?si=GeTLhLQzzgthnOOr"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->

    </div>
  </section>

  <!-- <head>
    <style>
        .video-container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 70vh; /* 70% of the viewport height */
        }
        .video-container iframe {
            width: 800px; /* 70% of the container's width */
            height: 450px; /* Maintain the aspect ratio */
        }
    </style>
</head>
<body>
    <div class="video-container">
        <h2 class="title is-3">Video</h2>
          <iframe src="https://www.youtube.com/embed/sksAVPmlDd8?si=GeTLhLQzzgthnOOr" frameborder="0" allowfullscreen></iframe>
    </div>
</body> -->




  <p style="margin-bottom: -0.5cm;"></p>

  <p style="margin-bottom: -0.5cm;"></p>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h3 class="title is-3 has-text-centered">Examples in MMVP</h3>
        <p align="middle">
          <img src="./static/videos/Mocap_20230422_172438.gif" width="384" height="384">
          <img src="./static/videos/Mocap_20230422_182056.gif" width="384" height="384">
        </p>
        <!-- <h2 class="subtitle has-text-centered">
          Throw ball        Standing long jump          
        </h2> -->

        <!-- <p align="middle">
          <img src="./static/videos/MoCap_20230422_182056.gif" width="512" height="512">
        </p>
        <h2 class="subtitle has-text-centered">
          Throw ball
        </h2> -->

        <p align="middle">
          <img src="./static/videos/Mocap_20230422_132043.gif" width="384" height="384">
          <img src="./static/videos/Mocap_20230422_151220.gif" width="384" height="384">
        </p>
        <!-- <h2 class="subtitle has-text-centered">
          Side step
        </h2> -->

        <!-- <p align="middle">
          <img src="./static/videos/MoCap_20230422_151220.gif" width="512" height="512">
        </p>
        <h2 class="subtitle has-text-centered">
          Rope skipping
        </h2> -->

      </div>
    </div>
  </section>



  <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
    <source src="./static/videos/demo_video.gif" type="video/mp4">
  </video> -->



  <p style="margin-bottom: -1.5cm;"></p>
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content is-size-6">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{Zhang2024MMVP,
  author    = {He Zhang, Shenghao Ren, Haolei Yuan, Jianhui Zhao, Fan Li, Shuangpeng Sun, Zhenghao Liang, Tao Yu, Qiu Shen, Xun Cao},
  title     = {MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors},
  journal   = {CVPR},
  year      = {2024},
}</code></pre>

<!-- <h2 class="title">Contact Us</h2>
<style>
  ul {
    list-style-type: circle;
  }
</style>
<ul>
  <li>For detailed questions about this work, please contact Jing Lin (jinglin.stu@gmail.com).</li>
  <li>We are looking for talented, motivated, and creative research and engineering interns working on human-centric visual understanding and generation topics. If you are interested, please send your CV to Ailing Zeng (zengailing@idea.edu.cn).</li>
</ul> -->
    </div>
  </section>





  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-size-6">
          <div class="content">
            <p>
              This website is created with this <a href="https://motion-x-dataset.github.io/">template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
